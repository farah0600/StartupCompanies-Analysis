{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 4: Beautiful Soup \n",
    "Data Engineering, the process of gathering and preparing data for analysis, is a very big part of Data Science.\n",
    "\n",
    "Datasets might not be formatted in the way you need (e.g. you have categorical features but your algorithm requires numerical features); or you might need to cross-reference some dataset to another that has a different format; or you might be dealing with a dataset that contains missing or invalid data.\n",
    "\n",
    "These are just a few examples of why data retrieval and cleaning are so important.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requests`:  Retrieving Data from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In HW1, you will be asked to retrieve some data from the Internet. `Python` has many built-in libraries that were developed over the years to do exactly that (e.g. `urllib`, `urllib2`, `urllib3`).\n",
    "\n",
    "However, these libraries are very low-level and somewhat hard to use. They become especially cumbersome when you need to issue POST requests or authenticate against a web service.\n",
    "\n",
    "Luckly, as with most tasks in `Python`, someone has developed a library that simplifies these tasks. In reality, the requests made both on this lab and on HW1 are fairly simple, and could easily be done using one of the built-in libraries. However, it is better to get acquainted to `requests` as soon as possible, since you will probably need it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You tell Python that you want to use a library with the import statement.\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the requests library was imported into our namespace, we can use the functions offered by it.\n",
    "\n",
    "In this case we'll use the appropriately named `get` function to issue a *GET* request. This is equivalent to typing a URL into your browser and hitting enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HU Wikipedia page\n",
    "req = requests.get(\"https://en.wikipedia.org/wiki/Harvard_University\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python is an Object Oriented language, and everything on it is an object. Even built-in functions such as `len` are just syntactic sugar for acting on object properties.\n",
    "\n",
    "We will not dwell too long on OO concepts, but some of Python's idiosyncrasies will be easier to understand if we spend a few minutes on this subject.\n",
    "\n",
    "When you evaluate an object itself, such as the `req` object we created above, Python will automatially call the `__str__()` or `__repr__()` method of that object. The default values for these methods are usually very simple and boring. The `req` object however has a custom implementation that shows the object type (i.e. `Response`) and the HTTP status number (200 means the request was successful)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to confirm, we will call the `type` function on the object to make sure it agrees with the value above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very nifty Python function is `dir`. You can use it to list all the properties of an object.\n",
    "\n",
    "By the way, properties starting with a single and double underscores are usually not meant to be called directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__attrs__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_content',\n",
       " '_content_consumed',\n",
       " '_next',\n",
       " 'apparent_encoding',\n",
       " 'close',\n",
       " 'connection',\n",
       " 'content',\n",
       " 'cookies',\n",
       " 'elapsed',\n",
       " 'encoding',\n",
       " 'headers',\n",
       " 'history',\n",
       " 'is_permanent_redirect',\n",
       " 'is_redirect',\n",
       " 'iter_content',\n",
       " 'iter_lines',\n",
       " 'json',\n",
       " 'links',\n",
       " 'next',\n",
       " 'ok',\n",
       " 'raise_for_status',\n",
       " 'raw',\n",
       " 'reason',\n",
       " 'request',\n",
       " 'status_code',\n",
       " 'text',\n",
       " 'url']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now `req` holds a reference to a *Request* object; but we are interested in the text associated with the web page, not the object itself.\n",
    "\n",
    "So the next step is to assign the value of the `text` property of this `Request` object to a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'span></span></span><span class=\"geo-multi-punct\">&#xfeff; / &#xfeff;</span><span class=\"geo-nondefault\"><span class=\"geo-dec\" title=\"Maps, aerial photos, and other data for this location\">42.37444°N 71.11694°W</span><span style=\"display:none\">&#xfeff; / <span class=\"geo\">42.37444; -71.11694</span></span></span></a></span></span></span></td></tr><tr><th scope=\"row\" class=\"infobox-label\" style=\"padding-right:0.65em;\">Campus</th><td class=\"infobox-data\">Urban, 209 acres (85&#160;ha)</td></tr><tr><th scope=\"row\" class=\"infobox-label\" style=\"padding-right:0.65em;\">Language</th><td class=\"infobox-data\">Mostly English</td></tr><tr><th scope=\"row\" class=\"infobox-label\" style=\"padding-right:0.65em;\">Newspaper</th><td class=\"infobox-data\"><i><a href=\"/wiki/The_Harvard_Crimson\" title=\"The Harvard Crimson\">The Harvard Crimson</a></i></td></tr><tr><th scope=\"row\" class=\"infobox-label\" style=\"padding-right:0.65em;\"><a href=\"/wiki/School_colors\" title=\"School colors\">Colors</a></th><td class=\"infobox-data\"><style data-mw-deduplicate=\"TemplateStyles:r981673959\">.mw-parser-output .legend{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .legend-color{display:inline-block;min-width:1.25em;height:1.25em;line-height:1.25;margin:1px 0;text-align:center;border:1px solid black;background-color:transparent;color:black}.mw-parser-output .legend-text{}</style><span class=\"legend-color\" style=\"background-color:#A51C30; color:white;\">&#160;</span> <a href=\"/wiki/Crimson\" title=\"Crimson\">Crimson</a><sup id=\"cite_ref-glance_4-1\" class=\"reference\"><a href=\"#cite_note-glance-4\">&#91;4&#93;</a></sup></td></tr><tr><th scope=\"row\" class=\"infobox-label\" style=\"padding-right:0.65em;\"><a href=\"/wiki/Athletic_nickname\" title=\"Athletic nickname\">Nickname</a></th><td class=\"infobox-data\"><a href=\"/wiki/Harvard_Crimson\" title=\"Harvard Crimson\">Harvard Crimson</a></td></tr><tr><th scope=\"row\" class=\"infobox-label\" style=\"padding-right:0.65em;\"><div style=\"display:inline-block; padding:0.1em 0;line-height:1.2em;\">Sporting affiliations</div></th><td class=\"infobox-data\"><a href=\"/wiki/NCAA_Division_I\" title=\"NCAA Division I\">NCAA Division I</a> – <a href=\"/wiki/Ivy_League\" title=\"Ivy League\">Ivy League</a></td></tr><tr><th scope=\"row\" class=\"infobox-label\" style=\"padding-right:0.65em;\">Mascot</th><td class=\"infobox-data\">John Harvard</td></tr><tr><th scope=\"row\" class=\"infobox-label\" style=\"padding-right:0.65em;\">Website</th><td class=\"infobox-data\"><span class=\"url\"><a rel=\"nofollow\" class=\"external text\" href=\"https://www.harvard.edu\">www<wbr />.harvard<wbr />.edu</a></span></td></tr><tr><td colspan=\"2\" class=\"infobox-full-data\"><a href=\"/wiki/File:Harvard_University_logo.svg\" class=\"image\"><img alt=\"Logotype of Harvard University\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/70/Harvard_University_logo.svg/220px-Harvard_University_logo.svg.png\" decoding=\"async\" width=\"220\" height=\"58\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/70/Harvard_University_logo.svg/330px-Harvard_University_logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/70/Harvard_University_logo.svg/440px-Harvard_University_logo.svg.png 2x\" data-file-width=\"1123\" data-file-height=\"294\" /></a></td></tr></tbody></table>\\n<p><b>Harvard University</b> is a <a href=\"/wiki/Private_university\" title=\"Private university\">private</a> <a href=\"/wiki/Ivy_League\" title=\"Ivy League\">Ivy League</a> <a href=\"/wiki/Research_university\" title=\"Research university\">research university</a> in <a href=\"/wiki/Cambridge,_Massachusetts\" title=\"Cambridge, Massachusetts\">Cambridge, Massachusetts</a>. Founded in 1636 as <b>Harvard College</b> and named for its first benefactor, the <a href=\"/wiki/History_of_the_Puritans_in_North_America\" title=\"History of the Puritans in North America\">Puritan</a> clergyman <a href=\"/wiki/John_Harvard_(clergyman)\" title=\"John Harvard (clergyman)\">John Harvard</a>, it is the oldest institution of higher learning in the United States and among the most prestigious in the world.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\">&#91;6&#93;</a></sup>\\n</p><p>The <a href=\"/wiki/Massachusetts_General_Court\" title=\"Massachusetts General Court\">Massachusetts colonial legislature</a> authorized Harvard\\'s founding, \"dreading to leave an illiterate <a href=\"/wiki/Minister_(Christianity)\" title=\"Minister (Christianity)\">ministry</a> to the churches, when our present ministers shall lie in the dust\"; though never formally affiliated with any <a href=\"/wiki/Religious_denomination\" title=\"Religious denomination\">denomination</a>, in its early years <a href=\"/wiki/Harvard_College\" title=\"Harvard College\">Harvard College</a> primarily trained <a href=\"/wiki/Congregationalism_in_the_United_States\" title=\"Congregationalism in the United States\">Congregational</a> clergy. Its curriculum and student body were gradually secularized during the 18th century, and by the 19th century, it had emerged as the central cultural establishment among <a href=\"/wiki/Boston_Brahmin\" title=\"Boston Brahmin\">the Boston elite</a>.<sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\">&#91;7&#93;</a></sup><sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\">&#91;8&#93;</a></sup>\\nFollowing the <a href=\"/wiki/American_Civil_War\" title=\"American Civil War\">American Civil War</a>, President <a href=\"/wiki/Charles_William_Eliot\" title=\"Charles William Eliot\">Charles William Eliot</a>\\'s long tenure (1869–1909) transformed the <a href=\"/wiki/Harvard_College\" title=\"Harvard College\">college</a> and affiliated professional schools into a modern <a href=\"/wiki/Research_university\" title=\"Research university\">research university</a>; Harvard became a founding member of the <a href=\"/wiki/Association_of_American_Universities\" title=\"Association of American Universities\">Association of American Universities</a> in 1900.<sup id=\"cite_ref-AAU_9-0\" class=\"reference\"><a href=\"#cite_note-AAU-9\">&#91;9&#93;</a></sup> <a href=\"/wiki/James_B._Conant\" title=\"James B. Conant\">James B. Conant</a> led the university through the <a href=\"/wiki/Great_Depression\" title=\"Great Depression\">Great Depression</a> and <a href=\"/wiki/World_War_II\" title=\"World War II\">World War II</a>, and liberalized admissions after the war.\\n</p><p>The university is composed of ten academic faculties plus the <a href=\"/wiki/Radcliffe_Institute_for_Advanced_Study\" class=\"mw-redirect\" title=\"Radcliffe Institute for Advanced Study\">Radcliffe Institute for Advanced Study</a>. <a href=\"/wiki/Harvard_Faculty_of_Arts_and_Sciences\" title=\"Harvard Faculty of Arts and Sciences\">Arts and Sciences</a> offers study in a wide range of <a href=\"/wiki/Academic_discipline\" title=\"Academic discipline\">academic disciplines</a> for undergraduates and for graduates, while the other faculties offer only graduate degrees, mostly <a href=\"/wiki/Professional_degree\" title=\"Professional degree\">professional</a>. Harvard has three main campuses:<sup id=\"cite_ref-10\" class=\"reference\"><a href=\"#cite_note-10\">&#91;10&#93;</a></sup>\\nthe 209-acre (85&#160;ha) Cambridge campus centered on <a href=\"/wiki/Harvard_Yard\" title=\"Harvard Yard\">Harvard Yard</a>; an adjoining campus immediately across the <a href=\"/wiki/Charles_River\" title=\"Charles River\">Charles River</a> in the <a href=\"/wiki/Allston\" title=\"Allston\">Allston</a> neighborhood of Boston; and the medical campus in Boston\\'s <a href=\"/wiki/Longwood_Medical_and_Academic_Area\" title=\"Longwood Medical and Academic Area\">Longwood Medical Area</a>.<sup id=\"cite_ref-Campus_11-0\" class=\"reference\"><a href=\"#cite_note-Campus-11\">&#91;11&#93;</a></sup> <a href=\"/wiki/Harvard_University_endowment\" title=\"Harvard University endowment\">Harvard\\'s endowment</a> is valued at $53.2&#160;billion, making it the <a href=\"/wiki/List_of_colleges_and_universities_in_the_United_States_by_endowment\" title=\"List of colleges and universities in the United States by endowment\">largest of any academic institution</a>.<sup id=\"cite_ref-Endowment_3-1\" class=\"reference\"><a href=\"#cite_note-Endowment-3\">&#91;3&#93;</a></sup> Endowment income helps enable the undergraduate college to <a href=\"/wiki/Need-blind_admission\" title=\"Need-blind admission\">admit students regardless of financial need</a> and provide generous financial aid with no loans.<sup id=\"cite_ref-12\" class=\"reference\"><a href=\"#cite_note-12\">&#91;12&#93;</a></sup> The <a href=\"/wiki/Harvard_Library\" title=\"Harvard Library\">Harvard Library</a> is the world\\'s largest academic library system, comprising 79 individual libraries holding about 20.4&#160;million items.<sup id=\"cite_ref-hlar_13-0\" class=\"reference\"><a href=\"#cite_note-hlar-13\">&#91;13&#93;</a></sup><sup id=\"cite_ref-largestlibs_14-0\" class=\"reference\"><a href=\"#cite_note-largestlibs-14\">&#91;14&#93;</a></sup><sup id=\"cite_ref-speaking_15-0\" class=\"reference\"><a href=\"#cite_note-speaking-15\">&#91;15&#93;</a></sup><sup id=\"cite_ref-Harvard_Media_Relations_16-0\" class=\"reference\"><a href=\"#cite_note-Harvard_Media_Relations-16\">&#91;16&#93;</a></sup>\\n</p><p>Harvard has more alumni, faculty, and researchers who have won <a href=\"/wiki/List_of_Nobel_laureates_by_university_affiliation\" title=\"List of Nobel laureates by university affiliation\">Nobel Prizes</a> (161) and <a href=\"/wiki/Fields_Medal\" title=\"Fields Medal\">Fields Medals</a> (18) than any other university in the world and more alumni who have been members of the <a href=\"/wiki/United_States_Congress\" title=\"United States Congress\">U.S. Congress</a>, <a href=\"/wiki/MacArthur_Fellows\" class=\"mw-redirect\" title=\"MacArthur Fellows\">MacArthur Fellows</a>, <a href=\"/wiki/Rhodes_Scholarship\" title=\"Rhodes Scholarship\">Rhodes Scholars</a> (375), <a href=\"/wiki/Marshall_Scholarship\" title=\"Marshall Scholarship\">Marshall Scholars</a> (255), and <a href=\"/wiki/Fulbright_Program\" title=\"Fulbright Program\">Fulbright Scholars</a> than any other university in the United States.<sup id=\"cite_ref-17\" class=\"reference\"><a href=\"#cite_'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "page = req.text\n",
    "page[20000:30000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have the text of the Harvard University Wikipedia page. But this mess of HTML tags would be a pain to parse manually. Which is why we will use another very cool Python library called `BeautifulSoup`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BeautifulSoup`\n",
    "\n",
    "Parsing data would be a breeze if we could always use well formatted data sources, such as CSV, JSON, or XML; but some formats such as HTML are at the same time a very popular and a pain to parse.\n",
    "\n",
    "One of the problems with HTML is that over the years browsers have evolved to be very forgiving of \"malformed\" syntax. Your browser is smart enough to detect some common problems, such as open tags, and correct them on the fly.\n",
    "\n",
    "Unfortunately, we do not have the time or patience to implement all the different corner cases, so we'll let BeautifulSoup do that for us.\n",
    "\n",
    "You'll notice that the `import` statement bellow is different from what we used for `requests`. The _from library import thing_ pattern is useful when you don't want to reference a function byt its full name (like we did with `requests.get`), but you also don't want to import every single thing on that library into your namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BeautifulSoup` can deal with `HTML` or `XML` data, so the next line parses the contents of the `page` variable using its `HTML` parser, and assigns the result of that to the `soup` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look much different from the `page` object representation. Let's make sure the two are different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like they are indeed different.\n",
    "\n",
    "`BeautifulSoup` objects have a cool little method that allows you to see the `HTML` content in a nice, indented way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Harvard University - Wikipedia\n",
      "  </title>\n",
      "  <script>\n",
      "   document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"27578fa5-4af7-4136-be3f-3840fc4d7e4c\",\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Harvard_University\",\"wgTitle\":\"Harvard University\",\"wgCurRevisionId\":1074567236,\"wgRevisionId\":1074567236,\"wgArticleId\":18426501,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"CS1 maint: location\",\"Webarchive template wayback links\",\"CS1: Julian–Gregorian uncertainty\",\"CS1 errors: generic name\"\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's our page!\n",
    "\n",
    "We can now reference elements of the `HTML` document in different ways. One very convenient way is by using the dot notation, which allows us to access the elements as if they were properties of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Harvard University - Wikipedia</title>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice for `HTML` elements that only appear once per page, such the the `title` tag. But what about elements that can appear multiple times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"mw-empty-elt\">\n",
       "</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Be careful with elements that show up multiple times.\n",
    "soup.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh Oh. Turns out the attribute syntax in `Beautiful` soup is what is called *syntactic sugar*. That's why it is safer to use the explicit commands behind that syntactic sugar I mentioned. These are:\n",
    "* `BeautifulSoup.find` for getting single elements, and \n",
    "* `BeautifulSoup.find_all` for retrieving multiple elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(soup.find_all(\"p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the Wikipedia page on your browser, you'll notice that it has a couple of tables in it. We will be working with the \"Demographics\" table, but first we need to find it.\n",
    "\n",
    "One of the `HTML` attributes that will be very useful to us is the `class` attribute.\n",
    "\n",
    "Getting the class of a single element is easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['box-Merge_from', 'plainlinks', 'metadata', 'ambox', 'ambox-move']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soup.table[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use a *list comprehension* to see all the tables that have a `class` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['box-Merge_from', 'plainlinks', 'metadata', 'ambox', 'ambox-move'],\n",
       " ['infobox', 'vcard'],\n",
       " ['toccolours'],\n",
       " ['infobox'],\n",
       " ['wikitable', 'sortable', 'collapsible', 'collapsed', 'floatright'],\n",
       " ['wikitable', 'sortable', 'collapsible', 'collapsed', 'floatright'],\n",
       " ['wikitable', 'sortable'],\n",
       " ['wikitable'],\n",
       " ['metadata', 'mbox-small'],\n",
       " ['nowraplinks', 'mw-collapsible', 'mw-collapsed', 'navbox-inner'],\n",
       " ['nowraplinks', 'navbox-subgroup'],\n",
       " ['nowraplinks', 'mw-collapsible', 'mw-collapsed', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'mw-collapsed', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'hlist', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'mw-collapsible', 'mw-collapsed', 'navbox-inner'],\n",
       " ['nowraplinks', 'hlist', 'mw-collapsible', 'autocollapse', 'navbox-inner'],\n",
       " ['nowraplinks', 'navbox-subgroup'],\n",
       " ['nowraplinks', 'hlist', 'mw-collapsible', 'autocollapse', 'navbox-inner']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the classes of all tables that have a class attribute set on them\n",
    "[t[\"class\"] for t in soup.find_all(\"table\") if t.get(\"class\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned, we will be using the Demographics table for this lab. The next cell contains the `HTML` elements of said table. We will render it in different parts of the notebook to make it easier to follow along the parsing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_demographics = soup.find_all(\"table\", \"wikitable\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"wikitable\" style=\"text-align:center; float:right; font-size:85%; margin-right:2em;\">\n",
       "<caption><i>Student demographics (Fall 2019)</i><sup class=\"reference\" id=\"cite_ref-112\"><a href=\"#cite_note-112\">[112]</a></sup>\n",
       "</caption>\n",
       "<tbody><tr>\n",
       "<th></th>\n",
       "<th>Undergrad</th>\n",
       "<th>Grad/prof\n",
       "</th></tr>\n",
       "<tr>\n",
       "<th>Asian\n",
       "</th>\n",
       "<td>21%</td>\n",
       "<td>13%\n",
       "</td></tr>\n",
       "<tr>\n",
       "<th>Black\n",
       "</th>\n",
       "<td>9%</td>\n",
       "<td>5%\n",
       "</td></tr>\n",
       "<tr>\n",
       "<th>Hispanic or Latino\n",
       "</th>\n",
       "<td>11%</td>\n",
       "<td>7%\n",
       "</td></tr>\n",
       "<tr>\n",
       "<th>White\n",
       "</th>\n",
       "<td>37%</td>\n",
       "<td>38%\n",
       "</td></tr>\n",
       "<tr>\n",
       "<th>Two or more races\n",
       "</th>\n",
       "<td>8%</td>\n",
       "<td>3%\n",
       "</td></tr>\n",
       "<tr>\n",
       "<th>International\n",
       "</th>\n",
       "<td>12%</td>\n",
       "<td>32%\n",
       "</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(str(table_demographics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll use a list comprehension to extract the rows (*tr*) elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr>\n",
      "<th></th>\n",
      "<th>Undergrad</th>\n",
      "<th>Grad/prof\n",
      "</th></tr>, <tr>\n",
      "<th>Asian\n",
      "</th>\n",
      "<td>21%</td>\n",
      "<td>13%\n",
      "</td></tr>, <tr>\n",
      "<th>Black\n",
      "</th>\n",
      "<td>9%</td>\n",
      "<td>5%\n",
      "</td></tr>, <tr>\n",
      "<th>Hispanic or Latino\n",
      "</th>\n",
      "<td>11%</td>\n",
      "<td>7%\n",
      "</td></tr>, <tr>\n",
      "<th>White\n",
      "</th>\n",
      "<td>37%</td>\n",
      "<td>38%\n",
      "</td></tr>, <tr>\n",
      "<th>Two or more races\n",
      "</th>\n",
      "<td>8%</td>\n",
      "<td>3%\n",
      "</td></tr>, <tr>\n",
      "<th>International\n",
      "</th>\n",
      "<td>12%</td>\n",
      "<td>32%\n",
      "</td></tr>]\n"
     ]
    }
   ],
   "source": [
    "rows = [row for row in table_demographics.find_all(\"tr\")]\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<tr>\n",
       "<th></th>\n",
       "<th>Undergrad</th>\n",
       "<th>Grad/prof\n",
       "</th></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "header_row = rows[0]\n",
    "HTML(str(header_row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then use a `lambda` expression to replace new line characters with spaces. `Lambda` expressions are to functions what list comprehensions are to lists: namely a more concise way to achieve the same thing.\n",
    "\n",
    "In reality, both lambda expressions and list comprehensions are a little different from their function and loop counterparts. But for the purposes of this class we can ignore those differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda expressions return the value of the expression inside it.\n",
    "# In this case, it will return a string with new line characters replaced by spaces.\n",
    "rem_nl = lambda s: s.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data\n",
    "Next we extract the text value of the columns. If you look at the table above, you'll see that we have three columns and six rows.\n",
    "\n",
    "Here we're doing the following:\n",
    "* Taking the first element (`Python` indices start at zero)\n",
    "* Iterating over the *th* elements inside it\n",
    "* Taking the text value of those elements\n",
    "\n",
    "We should end up with a list of column names.\n",
    "\n",
    "But there is one little caveat: the first column of the table is actually an empty string (look at the cell right above the row names). We could add it to our list and then remove it afterwards; but instead we will use the `if` statement inside the list comprehension to filter that out.\n",
    "\n",
    "In the following cell, `get_text` will return an empty string for the first cell of the table, which means that the test will fail and the value will not be added to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Undergrad', 'Grad/prof ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the if col.get_text() takes care of no-text in the upper left\n",
    "columns = [rem_nl(col.get_text()) for col in header_row.find_all(\"th\") if col.get_text()]\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same for the rows. Notice that since we have already parsed the header row, we will continue from the second row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Asian\\n',\n",
       " 'Black\\n',\n",
       " 'Hispanic or Latino\\n',\n",
       " 'White\\n',\n",
       " 'Two or more races\\n',\n",
       " 'International\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexes = [row.find(\"th\").get_text() for row in rows[1:]]\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to transform the string on the cells to integers.  To do this, we follow a very common `python` pattern:\n",
    "1. Check if the last character of the string is a percent sign\n",
    "2. If it is, then convert the characters before the percent sign to integers\n",
    "3. If one of the prior checks fails, return a value of `None`\n",
    "\n",
    "These steps can be conveniently packaged into a function using `if-else` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_num(s):\n",
    "    if s[-1] == \"%\":\n",
    "        return int(s[:-1])\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `Python` slices are open on the upper bound. So the `[:-1]` construct will return all elements of the string, except for the last."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another nice way to write our `to_num` function would be\n",
    "```python\n",
    "def to_num(s):\n",
    "    return int(s[:-1]) if s[-1] == \"%\" else None\n",
    "```\n",
    "Notice that we only had to write `return` one time and everything conveniently fits on one line.  I'll leave it up to you to decide if it's readable or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the `to_num` function in a list comprehension to parse the table values.\n",
    "\n",
    "Notice that we have two `for ... in ...` in this list comprehension. That is perfectly valid and somewhat common.\n",
    "\n",
    "Although there is no real limit to how many iterations you can perform at once, having more than two can be visually unpleasant, at which point either regular nested loops or saving intermediate comprehensions might be a better solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, None, 9, None, 11, None, 37, None, 8, None, 12, None]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = [to_num(value.get_text()) for row in rows[1:] for value in row.find_all(\"td\")]\n",
    "values"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
